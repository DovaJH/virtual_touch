#include <iostream>
#include <vector>
#include <cmath>
#include <chrono>

// FFmpeg
extern "C" {
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libswscale/swscale.h>
#include <libavutil/imgutils.h>
#include <libavdevice/avdevice.h>
}

// OpenCV
#include <opencv2/opencv.hpp>

// MediaPipe
#include "mediapipe/framework/calculator_framework.h"
#include "mediapipe/framework/formats/image_frame.h"
#include "mediapipe/framework/formats/image_frame_opencv.h"
#include "mediapipe/framework/formats/landmark.pb.h"
#include "mediapipe/gpu/gl_calculator_helper.h"
#include "mediapipe/gpu/gpu_buffer.h"
#include "mediapipe/gpu/gpu_shared_data_internal.h"

// libxdo (ë§ˆìš°ìŠ¤ ì œì–´)
#include <xdo.h>

// Pythonì˜ np.interpì™€ ë™ì¼í•œ ê¸°ëŠ¥ì„ í•˜ëŠ” í•¨ìˆ˜
float linear_interp(float x, float in_min, float in_max, float out_min, float out_max) {
    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;
}

// ì œìŠ¤ì²˜ ì¸ì‹ ë° ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
namespace GestureControl {
    // ì„¤ì •ê°’ (Pythonì˜ GestureRecognizer í´ë˜ìŠ¤ ë³€ìˆ˜ì™€ ë™ì¼)
    const int BOUNDARY_REVISION = 170;
    const float SMOOTH_ALPHA = 0.2f;
    const int SCROLL_DOWN_SPEED = -70;
    const int SCROLL_UP_SPEED = 70;
    const int CAM_WIDTH = 640;
    const int CAM_HEIGHT = 480;

    // ì†ê°€ë½ì´ í´ì¡ŒëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ (is_fingers_raised)
    std::vector<int> get_raised_fingers(const mediapipe::NormalizedLandmarkList& landmarks) {
        std::vector<int> fingers(5, 0);
        const int fingertip_indices[] = {4, 8, 12, 16, 20};

        // 1. ì—„ì§€ (x ì¢Œí‘œ ë¹„êµ)
        if (landmarks.landmark(fingertip_indices[0]).x() > landmarks.landmark(fingertip_indices[0] - 1).x()) {
            fingers[0] = 1;
        }

        // 2. ë‚˜ë¨¸ì§€ ë„¤ ì†ê°€ë½ (y ì¢Œí‘œ ë¹„êµ)
        for (int i = 1; i < 5; ++i) {
            if (landmarks.landmark(fingertip_indices[i]).y() < landmarks.landmark(fingertip_indices[i] - 2).y()) {
                fingers[i] = 1;
            }
        }
        return fingers;
    }

    // ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ (mouse_event)
    void handle_mouse_event(const std::vector<int>& fingers, const mediapipe::NormalizedLandmarkList& landmarks,
                              xdo_t* xdo, int scr_w, int scr_h,
                              float& prev_x, float& prev_y, bool& mouse_hold_state) {
        
        float index_finger_x = landmarks.landmark(8).x() * CAM_WIDTH;
        float index_finger_y = landmarks.landmark(8).y() * CAM_HEIGHT;
        float curr_x = prev_x, curr_y = prev_y;

        bool is_drag_gesture = (fingers[0] == 0 && fingers[1] == 1 && fingers[2] == 1 && fingers[3] == 0 && fingers[4] == 0);

        // ë“œë˜ê·¸ ìƒíƒœ ì²˜ë¦¬
        if (is_drag_gesture) {
            if (!mouse_hold_state) {
                xdo_mouse_down(xdo, CURRENTWINDOW, 1); // ì™¼ìª½ ë²„íŠ¼ ëˆ„ë¥´ê¸°
                mouse_hold_state = true;
            }
             // ë§ˆìš°ìŠ¤ ì´ë™ ë¡œì§ (ì•„ë˜ ê¸°ë³¸ ì´ë™ ë¡œì§ê³¼ ë™ì¼)
            float new_x = linear_interp(index_finger_x, BOUNDARY_REVISION, CAM_WIDTH - BOUNDARY_REVISION, 0, scr_w);
            float new_y = linear_interp(index_finger_y, BOUNDARY_REVISION, CAM_HEIGHT - BOUNDARY_REVISION, 0, scr_h);
            curr_x = prev_x + (new_x - prev_x) * SMOOTH_ALPHA;
            curr_y = prev_y + (new_y - prev_y) * SMOOTH_ALPHA;
            xdo_move_mouse(xdo, scr_w - curr_x, curr_y, 0);
        } else {
            if (mouse_hold_state) {
                xdo_mouse_up(xdo, CURRENTWINDOW, 1); // ì™¼ìª½ ë²„íŠ¼ ë–¼ê¸°
                mouse_hold_state = false;
            }
            
            // ì¼ë°˜ ì œìŠ¤ì²˜ ì²˜ë¦¬
            if (fingers[0] == 1) { // ì—„ì§€ë¥¼ í¸ ìƒíƒœ
                if (fingers[1] == 0 && fingers[2] == 0 && fingers[3] == 0 && fingers[4] == 0) {
                    xdo_click_window(xdo, CURRENTWINDOW, 1); // ì¢Œí´ë¦­
                } else if (fingers[1] == 1 && fingers[2] == 0 && fingers[3] == 0 && fingers[4] == 1) {
                    xdo_click_window(xdo, CURRENTWINDOW, 3); // ìš°í´ë¦­
                }
            } else { // ì—„ì§€ë¥¼ ì ‘ì€ ìƒíƒœ
                if (fingers[1] == 1 && fingers[2] == 0 && fingers[3] == 0 && fingers[4] == 0) { // ê²€ì§€ë§Œ í„: ë§ˆìš°ìŠ¤ ì´ë™
                    float new_x = linear_interp(index_finger_x, BOUNDARY_REVISION, CAM_WIDTH - BOUNDARY_REVISION, 0, scr_w);
                    float new_y = linear_interp(index_finger_y, BOUNDARY_REVISION, CAM_HEIGHT - BOUNDARY_REVISION, 0, scr_h);
                    
                    curr_x = prev_x + (new_x - prev_x) * SMOOTH_ALPHA;
                    curr_y = prev_y + (new_y - prev_y) * SMOOTH_ALPHA;
                    
                    xdo_move_mouse(xdo, scr_w - curr_x, curr_y, 0); // Python ì½”ë“œì˜ scr_w - curr_x ë°˜ì˜
                } else if (fingers == std::vector<int>{0,0,0,0,0}) { // ì£¼ë¨¹: ìŠ¤í¬ë¡¤ ë‹¤ìš´
                    xdo_click_window(xdo, CURRENTWINDOW, 5); // 5ë²ˆ ë²„íŠ¼ì´ ìŠ¤í¬ë¡¤ ë‹¤ìš´
                } else if (fingers[4] == 1 && fingers[1] == 0 && fingers[2] == 0 && fingers[3] == 0) { // ì†Œì§€ë§Œ í„: ìŠ¤í¬ë¡¤ ì—…
                    xdo_click_window(xdo, CURRENTWINDOW, 4); // 4ë²ˆ ë²„íŠ¼ì´ ìŠ¤í¬ë¡¤ ì—…
                }
            }
        }
        prev_x = curr_x;
        prev_y = curr_y;
    }
}


int main() {
    // 1. FFmpeg ì´ˆê¸°í™” (linux_input.cpp ê¸°ë°˜)
    avdevice_register_all();
    const char* dev_name = "/dev/video0";
    const AVInputFormat* inputFormat = av_find_input_format("v4l2");
    AVFormatContext* fmt_ctx = nullptr;
    AVDictionary* options = nullptr;
    av_dict_set(&options, "video_size", "640x480", 0);
    av_dict_set(&options, "framerate", "30", 0);

    if (avformat_open_input(&fmt_ctx, dev_name, inputFormat, &options) != 0) {
        std::cerr << "âŒ ì›¹ìº  ì—°ê²° ì‹¤íŒ¨!" << std::endl; return -1;
    }
    if (avformat_find_stream_info(fmt_ctx, nullptr) < 0) {
        std::cerr << "âš ï¸ ìŠ¤íŠ¸ë¦¼ ì •ë³´ ì½ê¸° ì‹¤íŒ¨!" << std::endl; return -1;
    }

    int video_stream_index = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, nullptr, 0);
    AVCodecParameters* codecpar = fmt_ctx->streams[video_stream_index]->codecpar;
    const AVCodec* codec = avcodec_find_decoder(codecpar->codec_id);
    AVCodecContext* codec_ctx = avcodec_alloc_context3(codec);
    avcodec_parameters_to_context(codec_ctx, codecpar);
    if (avcodec_open2(codec_ctx, codec, nullptr) < 0) {
        std::cerr << "â›” ì½”ë± ì´ˆê¸°í™” ì‹¤íŒ¨!" << std::endl; return -1;
    }

    AVPacket* pkt = av_packet_alloc();
    AVFrame* frame = av_frame_alloc();
    AVFrame* rgb_frame = av_frame_alloc();
    std::vector<uint8_t> buffer(av_image_get_buffer_size(AV_PIX_FMT_RGB24, codec_ctx->width, codec_ctx->height, 1));
    av_image_fill_arrays(rgb_frame->data, rgb_frame->linesize, buffer.data(), AV_PIX_FMT_RGB24, codec_ctx->width, codec_ctx->height, 1);
    
    SwsContext* sws_ctx = sws_getContext(codec_ctx->width, codec_ctx->height, codec_ctx->pix_fmt,
                                     codec_ctx->width, codec_ctx->height, AV_PIX_FMT_RGB24,
                                     SWS_BILINEAR, nullptr, nullptr, nullptr);

    // 2. MediaPipe ê·¸ë˜í”„ ì´ˆê¸°í™”
    mediapipe::CalculatorGraphConfig config;
    config.ParseFromString(R"pb(
        input_stream: "input_video"
        output_stream: "output_landmarks"

        # GPU ê°€ì†ì„ ìœ„í•œ ì„¤ì •
        node {
            calculator: "FlowLimiterCalculator"
            input_stream: "input_video"
            input_stream: "FINISHED:output_landmarks"
            input_stream_info: { tag_index: "FINISHED" back_edge: true }
            output_stream: "throttled_input_video"
        }

        node {
            calculator: "HandLandmarkTrackingGpu"
            input_stream: "IMAGE:throttled_input_video"
            output_stream: "LANDMARKS:output_landmarks"
            options: {
                [mediapipe.HandLandmarkTrackingGpuOptions.ext] {
                    max_num_hands: 1
                }
            }
        }
    )pb");

    mediapipe::CalculatorGraph graph;
    graph.Initialize(config);

    // GPU ë¦¬ì†ŒìŠ¤ ì„¤ì •
    auto gpu_resources = mediapipe::GpuResources::Create().ValueOrDie();
    graph.SetGpuResources(std::move(gpu_resources));
    mediapipe::GlCalculatorHelper gpu_helper;
    gpu_helper.InitializeForTest(graph.GetGpuResources().get());

    // ì…ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ í´ëŸ¬ ì¶”ê°€
    auto poller = graph.AddOutputStreamPoller("output_landmarks").ValueOrDie();
    graph.StartRun({});

    // 3. ë§ˆìš°ìŠ¤ ì œì–´ ë° ë³€ìˆ˜ ì´ˆê¸°í™”
    xdo_t* xdo = xdo_new(NULL);
    int screen_width, screen_height;
    xdo_get_desktop_dimensions(xdo, &screen_width, &screen_height, 0);

    float prev_x = 0.0f, prev_y = 0.0f;
    bool mouse_hold_state = false;
    auto prev_time = std::chrono::high_resolution_clock::now();
    
    std::cout << "ğŸ¬ ê°€ìƒ í„°ì¹˜ ì‹œì‘... (q í‚¤ ë˜ëŠ” Ctrl+Cë¡œ ì¢…ë£Œ)" << std::endl;

    // 4. ë©”ì¸ ë£¨í”„
    while (av_read_frame(fmt_ctx, pkt) >= 0) {
        if (pkt->stream_index == video_stream_index) {
            if (avcodec_send_packet(codec_ctx, pkt) == 0) {
                while (avcodec_receive_frame(codec_ctx, frame) == 0) {
                    // FFmpeg í”„ë ˆì„ì„ OpenCV Matìœ¼ë¡œ ë³€í™˜ (RGB)
                    sws_scale(sws_ctx, frame->data, frame->linesize, 0, codec_ctx->height, rgb_frame->data, rgb_frame->linesize);
                    cv::Mat input_mat(codec_ctx->height, codec_ctx->width, CV_8UC3, rgb_frame->data[0], rgb_frame->linesize[0]);
                    cv::Mat flipped_mat;
                    cv::flip(input_mat, flipped_mat, 1); // ì¢Œìš° ë°˜ì „

                    // MediaPipeì— í”„ë ˆì„ ì „ì†¡
                    auto input_frame = absl::make_unique<mediapipe::ImageFrame>(
                        mediapipe::ImageFormat::SRGB, flipped_mat.cols, flipped_mat.rows,
                        mediapipe::ImageFrame::kGlDefaultAlignmentBoundary);
                    cv::Mat input_frame_mat = mediapipe::formats::MatView(input_frame.get());
                    flipped_mat.copyTo(input_frame_mat);
                    
                    size_t frame_timestamp_us = std::chrono::duration_cast<std::chrono::microseconds>(
                        std::chrono::high_resolution_clock::now().time_since_epoch()).count();
                    
                    graph.AddPacketToInputStream("input_video", mediapipe::Adopt(input_frame.release()).At(mediapipe::Timestamp(frame_timestamp_us))).Ok();

                    // MediaPipeì—ì„œ ê²°ê³¼ ìˆ˜ì‹ 
                    mediapipe::Packet packet;
                    if (poller->Next(&packet)) {
                        auto& output_landmarks = packet.Get<std::vector<mediapipe::NormalizedLandmarkList>>();
                        if (!output_landmarks.empty()) {
                            const auto& hand_landmarks = output_landmarks[0];
                            
                            // ì œìŠ¤ì²˜ ë¶„ì„ ë° ë§ˆìš°ìŠ¤ ì œì–´
                            std::vector<int> fingers = GestureControl::get_raised_fingers(hand_landmarks);
                            GestureControl::handle_mouse_event(fingers, hand_landmarks, xdo, screen_width, screen_height, prev_x, prev_y, mouse_hold_state);

                            // ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° (ì‹œê°í™”)
                            for(const auto& landmark : hand_landmarks.landmark()){
                                cv::circle(flipped_mat, cv::Point(landmark.x() * flipped_mat.cols, landmark.y() * flipped_mat.rows), 5, cv::Scalar(255,0,255), cv::FILLED);
                            }
                        }
                    }

                    // FPS ê³„ì‚° ë° í‘œì‹œ
                    auto curr_time = std::chrono::high_resolution_clock::now();
                    double fps = 1.0 / std::chrono::duration_cast<std::chrono::duration<double>>(curr_time - prev_time).count();
                    prev_time = curr_time;
                    cv::putText(flipped_mat, std::to_string(static_cast<int>(fps)), cv::Point(20, 50), cv::FONT_HERSHEY_PLAIN, 3, cv::Scalar(0, 0, 0), 3);

                    cv::imshow("Virtual Touch C++", flipped_mat);
                    if (cv::waitKey(1) == 'q') goto end;
                }
            }
        }
        av_packet_unref(pkt);
    }

end:
    // 5. ë¦¬ì†ŒìŠ¤ í•´ì œ
    std::cout << "ğŸ›‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œ" << std::endl;
    graph.CloseInputStream("input_video");
    graph.WaitUntilDone();
    xdo_free(xdo);
    av_frame_free(&rgb_frame);
    av_frame_free(&frame);
    av_packet_free(&pkt);
    sws_freeContext(sws_ctx);
    avcodec_free_context(&codec_ctx);
    avformat_close_input(&fmt_ctx);
    cv::destroyAllWindows();
    return 0;
}