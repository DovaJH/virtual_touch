#include <iostream>
#include <vector>
#include <cmath>
#include <chrono>
#include <memory>
#include <mutex> // [ì¶”ê°€] ìŠ¤ë ˆë“œ ë™ê¸°í™”ë¥¼ ìœ„í•œ ë®¤í…ìŠ¤ í—¤ë”

// FFmpeg
extern "C" {
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libswscale/swscale.h>
#include <libavutil/imgutils.h>
#include <libavdevice/avdevice.h>
}

// OpenCV
#include <opencv2/opencv.hpp>

// 1. Status ë§¤í¬ë¡œê°€ í•„ìš”í•œ X11 ê´€ë ¨ í—¤ë”ë“¤ì„ ë¨¼ì € ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.
#include <X11/X.h>
#include <X11/Xlib.h>
#include <X11/extensions/XTest.h>

// 2. X11 í—¤ë” í¬í•¨ì´ ëë‚œ í›„, ì´ë¦„ ì¶©ëŒì„ ë§‰ê¸° ìœ„í•´ Status ë§¤í¬ë¡œë¥¼ í•´ì œí•©ë‹ˆë‹¤.
#undef Status

#include "mediapipe/framework/formats/image.h"
#include "mediapipe/tasks/cc/components/containers/landmark.h"
#include "mediapipe/tasks/cc/vision/hand_landmarker/hand_landmarker.h"

// [ì¶”ê°€] ìŠ¤ë ˆë“œ ê°„ ë°ì´í„° ë° ìƒíƒœ ê³µìœ ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
std::mutex landmarks_mutex;    // ë©”ì¸ ìŠ¤ë ˆë“œì™€ ì½œë°± ìŠ¤ë ˆë“œ ê°„ ë°ì´í„° ë™ê¸°í™”ë¥¼ ìœ„í•œ ë®¤í…ìŠ¤
std::vector<mediapipe::tasks::components::containers::NormalizedLandmark> latest_landmarks;
Display* global_display = nullptr; // X11 ë””ìŠ¤í”Œë ˆì´ í¬ì¸í„°
Window global_root_window; // ë£¨íŠ¸ ìœˆë„ìš° í•¸ë“¤
int global_screen_width, global_screen_height; // í™”ë©´ í¬ê¸°
float global_prev_x = 0.0f, global_prev_y = 0.0f; // ì´ì „ ë§ˆìš°ìŠ¤ ìœ„ì¹˜
bool global_mouse_hold_state = false; // ë§ˆìš°ìŠ¤ í™€ë“œ ìƒíƒœ

// Pythonì˜ np.interpì™€ ë™ì¼í•œ ê¸°ëŠ¥ì„ í•˜ëŠ” í•¨ìˆ˜
float linear_interp(float x, float in_min, float in_max, float out_min, float out_max) {
    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;
}

// ì œìŠ¤ì²˜ ì¸ì‹ ë° ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
namespace GestureControl {
    const int BOUNDARY_REVISION = 170;
    const float SMOOTH_ALPHA = 0.2f;
    const int CAM_WIDTH = 640;
    const int CAM_HEIGHT = 480;

    using LandmarkList = std::vector<mediapipe::tasks::components::containers::NormalizedLandmark>;

    void click_mouse(Display* display, unsigned int button) {
        XTestFakeButtonEvent(display, button, True, CurrentTime);
        XTestFakeButtonEvent(display, button, False, CurrentTime);
        XFlush(display);
    }

    std::vector<int> get_raised_fingers(const LandmarkList& landmarks) {
        std::vector<int> fingers(5, 0);
        const int fingertip_indices[] = {4, 8, 12, 16, 20};
        if (landmarks.size() < 21) return fingers;

        if (landmarks[fingertip_indices[0]].x > landmarks[fingertip_indices[0] - 1].x) {
            fingers[0] = 1;
        }
        for (int i = 1; i < 5; ++i) {
            if (landmarks[fingertip_indices[i]].y < landmarks[fingertip_indices[i] - 2].y) {
                fingers[i] = 1;
            }
        }
        return fingers;
    }

    // [ìˆ˜ì •] ë§ˆìš°ìŠ¤ ì œì–´ í•¨ìˆ˜ê°€ ì „ì—­ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½
    void handle_mouse_event(const std::vector<int>& fingers, const LandmarkList& landmarks) {
        if (landmarks.size() < 9) return;
        
        float index_finger_x = landmarks[8].x * CAM_WIDTH;
        float index_finger_y = landmarks[8].y * CAM_HEIGHT;
        float curr_x = global_prev_x, curr_y = global_prev_y;

        bool is_drag_gesture = (fingers[0] == 0 && fingers[1] == 1 && fingers[2] == 1 && fingers[3] == 0 && fingers[4] == 0);

        if (is_drag_gesture) {
            if (!global_mouse_hold_state) {
                XTestFakeButtonEvent(global_display, 1, True, CurrentTime);
                global_mouse_hold_state = true;
            }
            float new_x = linear_interp(index_finger_x, BOUNDARY_REVISION, CAM_WIDTH - BOUNDARY_REVISION, 0, global_screen_width);
            float new_y = linear_interp(index_finger_y, BOUNDARY_REVISION, CAM_HEIGHT - BOUNDARY_REVISION, 0, global_screen_height);
            curr_x = global_prev_x + (new_x - global_prev_x) * SMOOTH_ALPHA;
            curr_y = global_prev_y + (new_y - global_prev_y) * SMOOTH_ALPHA;
            
            XWarpPointer(global_display, NULL, global_root_window, 0, 0, 0, 0, curr_x, curr_y);
            XFlush(global_display);
        } else {
            if (global_mouse_hold_state) {
                XTestFakeButtonEvent(global_display, 1, False, CurrentTime);
                XFlush(global_display);
                global_mouse_hold_state = false;
            }
            if (fingers[0] == 1) {
                if (fingers[1] == 0 && fingers[2] == 0 && fingers[3] == 0 && fingers[4] == 0) click_mouse(global_display, 1);
                else if (fingers[1] == 1 && fingers[2] == 0 && fingers[3] == 0 && fingers[4] == 1) click_mouse(global_display, 3);
            } else {
                if (fingers[1] == 1 && fingers[2] == 0 && fingers[3] == 0 && fingers[4] == 0) {
                    float new_x = linear_interp(index_finger_x, BOUNDARY_REVISION, CAM_WIDTH - BOUNDARY_REVISION, 0, global_screen_width);
                    float new_y = linear_interp(index_finger_y, BOUNDARY_REVISION, CAM_HEIGHT - BOUNDARY_REVISION, 0, global_screen_height);
                    curr_x = global_prev_x + (new_x - global_prev_x) * SMOOTH_ALPHA;
                    curr_y = global_prev_y + (new_y - global_prev_y) * SMOOTH_ALPHA;
                    XWarpPointer(global_display, NULL, global_root_window, 0, 0, 0, 0, curr_x, curr_y);
                    XFlush(global_display);
                } else if (fingers == std::vector<int>{0,0,0,0,0}) click_mouse(global_display, 5);
                else if (fingers[4] == 1 && fingers[1] == 0 && fingers[2] == 0 && fingers[3] == 0) click_mouse(global_display, 4);
            }
        }
        global_prev_x = curr_x;
        global_prev_y = curr_y;
    }

    // [ì¶”ê°€] LIVE_STREAM ëª¨ë“œë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜ ì •ì˜
    void OnLandmarksDetected(
        absl::StatusOr<mediapipe::tasks::vision::hand_landmarker::HandLandmarkerResult> result, // <-- [ìˆ˜ì •] íƒ€ì… ë³€ê²½
        const mediapipe::Image& image, int64_t timestamp_ms) {
    
        // [ì¶”ê°€] ê²°ê³¼ê°€ ìœ íš¨í•œì§€ (OKì¸ì§€) ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.
        if (!result.ok()) {
            // ì—ëŸ¬ê°€ ë°œìƒí–ˆìœ¼ë©´ ì²˜ë¦¬ (ì˜ˆ: ë¡œê·¸ ì¶œë ¥)
            // std::cerr << "Landmark detection failed: " << result.status() << std::endl;
            return;
        }
    
        // [ìˆ˜ì •] ê²°ê³¼ì— ì ‘ê·¼í•  ë•Œ .value()ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        if (!result->hand_landmarks.empty()) {
            const auto& current_frame_landmarks = result->hand_landmarks[0].landmarks;
    
            // ì œìŠ¤ì²˜ ë¶„ì„ ë° ë§ˆìš°ìŠ¤ ì œì–´ ë¡œì§ (ì´ì „ê³¼ ë™ì¼)
            std::vector<int> fingers = get_raised_fingers(current_frame_landmarks);
            handle_mouse_event(fingers, current_frame_landmarks);
    
            // í™”ë©´ì— ê·¸ë¦¬ê¸° ìœ„í•œ ë°ì´í„°ë¥¼ ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ì „ë‹¬ (ë®¤í…ìŠ¤ ì‚¬ìš©)
            std::lock_guard<std::mutex> lock(landmarks_mutex);
            latest_landmarks = current_frame_landmarks;
        } else {
            // ì†ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ê·¸ë¦¬ê¸°ìš© ë°ì´í„°ë„ ë¹„ì›€
            std::lock_guard<std::mutex> lock(landmarks_mutex);
            latest_landmarks.clear();
        }
    }
}

int main() {
    avdevice_register_all();
    const char* dev_name = "/dev/video0";
    const AVInputFormat* inputFormat = av_find_input_format("v4l2");
    AVFormatContext* fmt_ctx = nullptr;
    AVDictionary* ffmpeg_options = nullptr;
    av_dict_set(&ffmpeg_options, "video_size", "640x480", 0);
    av_dict_set(&ffmpeg_options, "framerate", "30", 0);

    if (avformat_open_input(&fmt_ctx, dev_name, inputFormat, &ffmpeg_options) != 0) {
        std::cerr << "âŒ ì›¹ìº  ì—°ê²° ì‹¤íŒ¨!" << std::endl; return -1;
    }
    if (avformat_find_stream_info(fmt_ctx, nullptr) < 0) {
        std::cerr << "âš ï¸ ìŠ¤íŠ¸ë¦¼ ì •ë³´ ì½ê¸° ì‹¤íŒ¨!" << std::endl; return -1;
    }

    int video_stream_index = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, nullptr, 0);
    if (video_stream_index < 0) {
        std::cerr << "â›” ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!" << std::endl; return -1;
    }
    AVCodecParameters* codecpar = fmt_ctx->streams[video_stream_index]->codecpar;
    const AVCodec* codec = avcodec_find_decoder(codecpar->codec_id);
    AVCodecContext* codec_ctx = avcodec_alloc_context3(codec);
    avcodec_parameters_to_context(codec_ctx, codecpar);
    if (avcodec_open2(codec_ctx, codec, nullptr) < 0) {
        std::cerr << "â›” ì½”ë± ì´ˆê¸°í™” ì‹¤íŒ¨!" << std::endl; return -1;
    }

    AVPacket* pkt = av_packet_alloc();
    AVFrame* frame = av_frame_alloc();
    AVFrame* rgb_frame = av_frame_alloc();
    std::vector<uint8_t> buffer(av_image_get_buffer_size(AV_PIX_FMT_RGB24, codec_ctx->width, codec_ctx->height, 1));
    av_image_fill_arrays(rgb_frame->data, rgb_frame->linesize, buffer.data(), AV_PIX_FMT_RGB24, codec_ctx->width, codec_ctx->height, 1);
    SwsContext* sws_ctx = sws_getContext(codec_ctx->width, codec_ctx->height, codec_ctx->pix_fmt, codec_ctx->width, codec_ctx->height, AV_PIX_FMT_RGB24, SWS_BILINEAR, nullptr, nullptr, nullptr);

    // [ìˆ˜ì •] X11 ì´ˆê¸°í™” í›„ ì½œë°± í•¨ìˆ˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì „ì—­ ë³€ìˆ˜ì— í• ë‹¹
    Display* display = XOpenDisplay(NULL);
    if (display == NULL) { std::cerr << "â›” X ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!" << std::endl; return -1; }
    global_display = display;
    global_root_window = DefaultRootWindow(display);
    Window dummy_win; int dummy_int; unsigned int dummy_uint;
    XGetGeometry(display, global_root_window, &dummy_win, &dummy_int, &dummy_int, (unsigned int*)&global_screen_width, (unsigned int*)&global_screen_height, &dummy_uint, &dummy_uint);
    
    // [ìˆ˜ì •] HandLandmarker ì˜µì…˜ì„ LIVE_STREAM ëª¨ë“œë¡œ ì„¤ì •
    auto hand_landmarker_options = std::make_unique<mediapipe::tasks::vision::hand_landmarker::HandLandmarkerOptions>();
    hand_landmarker_options->base_options.model_asset_path = "mediapipe/examples/desktop/my_virtual_touch/hand_landmarker.task";
    hand_landmarker_options->running_mode = mediapipe::tasks::vision::core::RunningMode::LIVE_STREAM;
    hand_landmarker_options->num_hands = 1;
    hand_landmarker_options->result_callback = GestureControl::OnLandmarksDetected; // ì½œë°± í•¨ìˆ˜ ì§€ì •

    auto landmarker_result = mediapipe::tasks::vision::hand_landmarker::HandLandmarker::Create(std::move(hand_landmarker_options));
    if (!landmarker_result.ok()) {
        std::cerr << "â›” HandLandmarker ìƒì„± ì‹¤íŒ¨! " << landmarker_result.status() << std::endl;
        return -1;
    }
    std::unique_ptr<mediapipe::tasks::vision::hand_landmarker::HandLandmarker> landmarker = std::move(landmarker_result.value());

    auto prev_time = std::chrono::high_resolution_clock::now();
    auto start_time = std::chrono::high_resolution_clock::now();
    std::cout << "ğŸ¬ ê°€ìƒ í„°ì¹˜ ì‹œì‘... (q í‚¤ ë˜ëŠ” Ctrl+Cë¡œ ì¢…ë£Œ)" << std::endl;

    while (av_read_frame(fmt_ctx, pkt) >= 0) {
        if (pkt->stream_index == video_stream_index) {
            if (avcodec_send_packet(codec_ctx, pkt) == 0) {
                while (avcodec_receive_frame(codec_ctx, frame) == 0) {
                    sws_scale(sws_ctx, frame->data, frame->linesize, 0, codec_ctx->height, rgb_frame->data, rgb_frame->linesize);
                    cv::Mat input_mat(codec_ctx->height, codec_ctx->width, CV_8UC3, rgb_frame->data[0], rgb_frame->linesize[0]);

                     // [ì¶”ê°€] OpenCVì˜ BGR í˜•ì‹ì— ë§ê²Œ ìƒ‰ìƒ ì±„ë„ ìˆœì„œë¥¼ RGBì—ì„œ BGRë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                     cv::Mat bgr_mat;
                     cv::cvtColor(input_mat, bgr_mat, cv::COLOR_RGB2BGR);
 

                    cv::Mat flipped_mat;
                    cv::flip(bgr_mat, flipped_mat, 1);

                    // [ìˆ˜ì •] DetectAsyncë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ì ìœ¼ë¡œ ëœë“œë§ˆí¬ ê²€ì¶œ ìš”ì²­
                    auto now = std::chrono::high_resolution_clock::now();
                    int64_t timestamp_ms = std::chrono::duration_cast<std::chrono::milliseconds>(now - start_time).count();
                    
                    // 1. MediaPipeê°€ ì†Œìœ í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ImageFrameì„ ìƒì„±í•©ë‹ˆë‹¤.
                    //    ì´ë ‡ê²Œ í•˜ë©´ ì´ í”„ë ˆì„ì˜ ìƒëª…ì£¼ê¸°ëŠ” MediaPipeê°€ ê´€ë¦¬í•˜ê²Œ ë©ë‹ˆë‹¤.
                    auto mp_image_frame = std::make_shared<mediapipe::ImageFrame>(
                    mediapipe::ImageFormat::SRGB, flipped_mat.cols, flipped_mat.rows);

                    // 2. OpenCV Matì˜ ë°ì´í„°ë¥¼ ìƒˆë¡œ ìƒì„±í•œ ImageFrameì˜ ë²„í¼ë¡œ ì§ì ‘ ë³µì‚¬í•©ë‹ˆë‹¤.
                    memcpy(mp_image_frame->MutablePixelData(), flipped_mat.data, flipped_mat.total() * flipped_mat.elemSize());

                    mediapipe::Image mp_image(mp_image_frame);
                    
                    landmarker->DetectAsync(mp_image, timestamp_ms);

                    // [ìˆ˜ì •] ë©”ì¸ ìŠ¤ë ˆë“œëŠ” í™”ë©´ì— ê·¸ë¦¬ëŠ” ì—­í• ë§Œ ìˆ˜í–‰
                    GestureControl::LandmarkList landmarks_to_draw;
                    {
                        // ë®¤í…ìŠ¤ë¡œ ë³´í˜¸í•˜ë©° ì½œë°± ìŠ¤ë ˆë“œê°€ ì—…ë°ì´íŠ¸í•œ ìµœì‹  ëœë“œë§ˆí¬ ë°ì´í„°ë¥¼ ë³µì‚¬
                        std::lock_guard<std::mutex> lock(landmarks_mutex);
                        landmarks_to_draw = latest_landmarks;
                    }
                    
                    if (!landmarks_to_draw.empty()) {
                        for(const auto& landmark : landmarks_to_draw){
                            cv::circle(flipped_mat, cv::Point(landmark.x * flipped_mat.cols, landmark.y * flipped_mat.rows), 5, cv::Scalar(255,0,255), cv::FILLED);
                        }
                    }

                    auto curr_time = std::chrono::high_resolution_clock::now();
                    double fps = 1.0 / std::chrono::duration_cast<std::chrono::duration<double>>(curr_time - prev_time).count();
                    prev_time = curr_time;
                    cv::putText(flipped_mat, std::to_string(static_cast<int>(fps)), cv::Point(20, 50), cv::FONT_HERSHEY_PLAIN, 3, cv::Scalar(0, 255, 0), 3);
                    cv::imshow("Virtual Touch C++", flipped_mat);
                    if (cv::waitKey(1) == 'q') goto end;
                }
            }
        }
        av_packet_unref(pkt);
    }
end:
    std::cout << "ğŸ›‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œ" << std::endl;
    
    // [ì¶”ê°€] HandLandmarker ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    landmarker->Close();

    XCloseDisplay(display);
    av_frame_free(&rgb_frame);
    av_frame_free(&frame);
    av_packet_free(&pkt);
    sws_freeContext(sws_ctx);
    avcodec_free_context(&codec_ctx);
    avformat_close_input(&fmt_ctx);
    cv::destroyAllWindows();
    return 0;
}